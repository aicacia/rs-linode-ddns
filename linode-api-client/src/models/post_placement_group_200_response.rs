/*
 * Akamai: Linode API
 *
 * Add a Cloud Computing instance so you can build, release, and scale applications faster with virtual machines. 
 *
 * The version of the OpenAPI document: 4.193.0
 * Contact: jperez@linode.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct PostPlacementGroup200Response {
    /// The placement group's ID. You need to provide it for all operations that affect it.
    #[serde(rename = "id", skip_serializing_if = "Option::is_none")]
    pub id: Option<i32>,
    /// Whether all of the compute instances in your placement group are compliant. If `true`, all compute instances meet either the grouped-together or spread-apart model, which you determine through your selected `placement_group_type`. If `false`, a compute instance is out of this compliance. For example, assume you've set `anti-affinity:local` as your `placement_group_type` and your group already has three qualifying compute instances on separate hosts, to support the spread-apart model. If a fourth compute instance is assigned that's on the same host as one of the existing three, the placement group is non-compliant. Enforce compliance in your group by setting a `placement_group_policy`.  > ðŸ“˜ > > Fixing compliance is not self-service. You need to wait for our assistance to physically move compute instances to make the group compliant again.
    #[serde(rename = "is_compliant", skip_serializing_if = "Option::is_none")]
    pub is_compliant: Option<bool>,
    /// __Filterable__ The unique name set for the placement group. A label has these constraints:  - It needs to begin and end with an alphanumeric character. - It can only consist of alphanumeric characters, hyphens (`-`), underscores (`_`) or periods (`.`).
    #[serde(rename = "label", skip_serializing_if = "Option::is_none")]
    pub label: Option<String>,
    /// An array of compute instances included in the placement group.
    #[serde(rename = "members", skip_serializing_if = "Option::is_none")]
    pub members: Option<Vec<models::GetPlacementGroups200ResponseDataInnerMembersInner>>,
    /// How requests to add future compute instances to your placement group are handled, and whether it remains compliant:  - `strict`. Don't assign a new compute instance if it breaks the grouped-together or spread-apart model set by the `placement_group_type`. Use this to ensure the placement group stays compliant (`is_compliant: true`). - `flexible`. Assign a new compute instance, even if it breaks the grouped-together or spread-apart model set by the `placement_group_type`. This makes the group non-compliant (`is_compliant: false`). You need to wait for Akamai to move the offending compute instance to make it compliant again, once the necessary capacity is available in the region. Offers flexibility to add future compute instances if compliance isn't an immediate concern.  <<LB>>  > ðŸ“˜ > > In rare cases, non-compliance can occur with a `strict` placement group if Akamai needs to failover or migrate your compute instances for maintenance. Fixing non-compliance for a `strict` placement group is prioritized over a `flexible` group.
    #[serde(rename = "placement_group_policy", skip_serializing_if = "Option::is_none")]
    pub placement_group_policy: Option<PlacementGroupPolicyEnum>,
    /// __Filterable__, __Read-only__ How compute instances are distributed in your placement group. A `placement_group_type` using anti-affinity (`anti-affinity:local`) places compute instances in separate hosts, but still in the same region. This best supports the spread-apart model for high availability. A `placement_group_type` using affinity places compute instances physically close together, possibly on the same host. This supports the grouped-together model for low-latency.  > ðŸ“˜ > > Currently, only `anti_affinity:local` is available for `placement_group_type`.
    #[serde(rename = "placement_group_type", skip_serializing_if = "Option::is_none")]
    pub placement_group_type: Option<PlacementGroupTypeEnum>,
    /// __Filterable__, __Read-only__ The [region](https://techdocs.akamai.com/linode-api/reference/get-regions) where the placement group was deployed.
    #[serde(rename = "region", skip_serializing_if = "Option::is_none")]
    pub region: Option<String>,
}

impl PostPlacementGroup200Response {
    pub fn new() -> PostPlacementGroup200Response {
        PostPlacementGroup200Response {
            id: None,
            is_compliant: None,
            label: None,
            members: None,
            placement_group_policy: None,
            placement_group_type: None,
            region: None,
        }
    }
}
/// How requests to add future compute instances to your placement group are handled, and whether it remains compliant:  - `strict`. Don't assign a new compute instance if it breaks the grouped-together or spread-apart model set by the `placement_group_type`. Use this to ensure the placement group stays compliant (`is_compliant: true`). - `flexible`. Assign a new compute instance, even if it breaks the grouped-together or spread-apart model set by the `placement_group_type`. This makes the group non-compliant (`is_compliant: false`). You need to wait for Akamai to move the offending compute instance to make it compliant again, once the necessary capacity is available in the region. Offers flexibility to add future compute instances if compliance isn't an immediate concern.  <<LB>>  > ðŸ“˜ > > In rare cases, non-compliance can occur with a `strict` placement group if Akamai needs to failover or migrate your compute instances for maintenance. Fixing non-compliance for a `strict` placement group is prioritized over a `flexible` group.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum PlacementGroupPolicyEnum {
    #[serde(rename = "strict")]
    Strict,
    #[serde(rename = "flexible")]
    Flexible,
}

impl Default for PlacementGroupPolicyEnum {
    fn default() -> PlacementGroupPolicyEnum {
        Self::Strict
    }
}
/// __Filterable__, __Read-only__ How compute instances are distributed in your placement group. A `placement_group_type` using anti-affinity (`anti-affinity:local`) places compute instances in separate hosts, but still in the same region. This best supports the spread-apart model for high availability. A `placement_group_type` using affinity places compute instances physically close together, possibly on the same host. This supports the grouped-together model for low-latency.  > ðŸ“˜ > > Currently, only `anti_affinity:local` is available for `placement_group_type`.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum PlacementGroupTypeEnum {
    #[serde(rename = "anti_affinity:local")]
    AntiAffinityColonLocal,
}

impl Default for PlacementGroupTypeEnum {
    fn default() -> PlacementGroupTypeEnum {
        Self::AntiAffinityColonLocal
    }
}

